{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer\n",
    "from sklearn import metrics \n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# print (pd.__name__, pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "text = pd.read_pickle(\"../data/movies_lines_train.p\")\n",
    "text_all = pd.read_pickle(\"../data/movies.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(304354, 9)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender_to</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>gender_from</th>\n",
       "      <th>char_id_from</th>\n",
       "      <th>char_id_to</th>\n",
       "      <th>line_id</th>\n",
       "      <th>words</th>\n",
       "      <th>movie_year</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m</td>\n",
       "      <td>m0</td>\n",
       "      <td>f</td>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>L194</td>\n",
       "      <td>we make quick roxanne korrine andrew barrett i...</td>\n",
       "      <td>1999</td>\n",
       "      <td>comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>m</td>\n",
       "      <td>m0</td>\n",
       "      <td>f</td>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>L195</td>\n",
       "      <td>well i think we start pronunciation okay you</td>\n",
       "      <td>1999</td>\n",
       "      <td>comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>m</td>\n",
       "      <td>m0</td>\n",
       "      <td>f</td>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>L196</td>\n",
       "      <td>hacking gagging spit part please</td>\n",
       "      <td>1999</td>\n",
       "      <td>comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>m</td>\n",
       "      <td>m0</td>\n",
       "      <td>f</td>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>L197</td>\n",
       "      <td>okay bout we try french cuisine saturday night</td>\n",
       "      <td>1999</td>\n",
       "      <td>comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>m</td>\n",
       "      <td>m0</td>\n",
       "      <td>f</td>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>L198</td>\n",
       "      <td>you ask me cute your name</td>\n",
       "      <td>1999</td>\n",
       "      <td>comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender_to movie_id gender_from char_id_from char_id_to line_id  \\\n",
       "0         m       m0           f           u0         u2    L194   \n",
       "1         m       m0           f           u0         u2    L195   \n",
       "2         m       m0           f           u0         u2    L196   \n",
       "3         m       m0           f           u0         u2    L197   \n",
       "4         m       m0           f           u0         u2    L198   \n",
       "\n",
       "                                               words movie_year   genre  \n",
       "0  we make quick roxanne korrine andrew barrett i...       1999  comedy  \n",
       "1       well i think we start pronunciation okay you       1999  comedy  \n",
       "2                   hacking gagging spit part please       1999  comedy  \n",
       "3     okay bout we try french cuisine saturday night       1999  comedy  \n",
       "4                          you ask me cute your name       1999  comedy  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Common n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def grams_df(df, numgrams):\n",
    "\n",
    "    grams_df = pd.DataFrame({'grams': [], 'line_id': []})\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        #print(index)\n",
    "        #create list of bigrams for each text\n",
    "        text = row['words']    \n",
    "        token = nltk.word_tokenize(text)\n",
    "        grams_list = list(ngrams(token, numgrams))\n",
    "        #grams_list = [gram for gram in grams]\n",
    "\n",
    "        #create dict of ngrams\n",
    "        line = row['line_id']\n",
    "        gen = row['gender_from']\n",
    "        d = {'grams': grams_list, 'line_id': np.repeat(line, len(grams_list)), 'gender_from': np.repeat(gen, len(grams_list))}\n",
    "        grams_df = pd.concat([grams_df, pd.DataFrame(d)], axis = 0)\n",
    "        \n",
    "    return grams_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test = text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "grams_df = grams_df(test,3)\n",
    "grams_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "bigrams = grams_df(text[:10000],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "bigrams = grams_df(text[:50000],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "bigrams['grams'].value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# remove unknown gender\n",
    "bigrams = bigrams[bigrams['gender_from'] != '?']\n",
    "\n",
    "# get counts\n",
    "grouped = bigrams.groupby(['gender_from', 'grams']).count()\n",
    "g = grouped['line_id'].groupby(level=0, group_keys=False).apply(lambda x: x.sort_values(ascending=False).head(10))\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "bigrams_genre = pd.merge(bigrams, text[['genre', 'line_id']], on = 'line_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "bigrams_genre.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "grouped2 = bigrams_genre.groupby(['genre','gender_from', 'grams']).count()\n",
    "g2 = grouped2['line_id'].groupby(['genre', 'gender_from'], group_keys=False).apply(lambda x: x.sort_values(ascending=False).head(5))\n",
    "g2.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Topic Modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#mallet_path = '/Users/jasmindial/Desktop/mallet-2.0.8/bin/mallet'\n",
    "#mallet_path = \"../mallet-2.0.8/bin/mallet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# remove terms with low frequency\n",
    "\n",
    "# get all the words\n",
    "total = []\n",
    "for index, row in text.iterrows():\n",
    "    Text = row['words']    \n",
    "    token = nltk.word_tokenize(Text)\n",
    "    total.extend(token) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "high_freq = nltk.FreqDist(total).most_common(round(.9*text.shape[0]))\n",
    "high_freq = [word for (word, count) in high_freq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_words(x):\n",
    "\n",
    "    tags = ['IN', 'CD', 'MD']\n",
    "    text = nltk.word_tokenize(x)\n",
    "    tags = nltk.pos_tag(text)\n",
    "    \n",
    "    # remove non-meaningful POS & very low-frequency\n",
    "    words = [word for (word, tag) in tags if tag not in tags if word in high_freq]\n",
    "    \n",
    "    return words\n",
    "\n",
    "text['words'] = text['words'].apply(clean_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# get two separate texts from the training dataframe\n",
    "women = text[text['gender_from'] == 'f']\n",
    "women.name = 'women'\n",
    "men = text[text['gender_from'] == 'm']\n",
    "men.name = 'men'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51762, 9)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "women.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125707, 9)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "men.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "stopWords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# source: https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/\n",
    "# trying the genism version "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def add_ngrams(texts):\n",
    "    \n",
    "    bigram = gensim.models.Phrases(texts, common_terms=stopWords, min_count=5, threshold=25) \n",
    "    trigram = gensim.models.Phrases(bigram[texts], threshold=25)  \n",
    "\n",
    "    bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "    trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "    \n",
    "    texts = [[word for word in simple_preprocess(str(doc)) if word not in stopWords] for doc in texts]\n",
    "    texts = [bigram_mod[doc] for doc in texts]\n",
    "    texts = [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "    \n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def prep_for_model(series):\n",
    "    \n",
    "    # convert to list\n",
    "    data = series.values.tolist()\n",
    "\n",
    "    # tokenize \n",
    "    def sent_to_words(sentences):\n",
    "        for sentence in sentences:\n",
    "            yield(gensim.utils.simple_preprocess(str(sentence)))  \n",
    "\n",
    "    data_words = list(sent_to_words(data)) \n",
    "    data_words = add_ngrams(data_words)\n",
    "    \n",
    "    # create dictionary\n",
    "    id2word = corpora.Dictionary(data_words)\n",
    "\n",
    "    # Term Document Frequency\n",
    "    corpus = [id2word.doc2bow(text) for text in data_words]\n",
    "    \n",
    "    return data_words, id2word, corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/gensim/models/phrases.py:494: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "223"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just testing \n",
    "data_words, id2word, corpus = prep_for_model(women.words)\n",
    "# make sure grams are working\n",
    "len(set([word for sent in data_words for word in sent if \"_\" in word]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# doesn't like this\n",
    "#lda_model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=8, id2word=id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        #print (num_topics)\n",
    "        lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,id2word=id2word, num_topics=num_topics, \n",
    "                                                    random_state=100, update_every=1, chunksize=100, passes=10,\n",
    "                                                    alpha='auto', per_word_topics=True)\n",
    "        #lda_model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=id2word)\n",
    "        model_list.append(lda_model)\n",
    "        coherencemodel = CoherenceModel(model=lda_model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# run models and get coherence values\n",
    "# model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus,\n",
    "                                                        #texts=data_words, start=3, limit=13, step=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "women\n",
      "(7808, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/gensim/models/phrases.py:494: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11905, 9)\n",
      "(14644, 9)\n",
      "(6612, 9)\n",
      "men\n",
      "(29431, 9)\n",
      "(28995, 9)\n",
      "(28992, 9)\n",
      "(15973, 9)\n"
     ]
    }
   ],
   "source": [
    "# run topic modeling for both gender scripts \n",
    "# this takes a while :)\n",
    "\n",
    "common_genres = [\"action\", \"drama\", \"comedy\", \"crime\"]\n",
    "#dictionary of models\n",
    "d = {genre:{} for genre in common_genres}\n",
    "\n",
    "topics = []\n",
    "coherence = []\n",
    "\n",
    "for gen in [women, men]:\n",
    "    print (gen.name)\n",
    "    for x in common_genres:\n",
    "        df = gen[gen.genre == x]\n",
    "        print(df.shape)\n",
    "        group = df.words\n",
    "    \n",
    "        data_words, id2word, corpus = prep_for_model(group)\n",
    "        model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus,\n",
    "                                                            texts=data_words, start=4, limit=13, step=2)\n",
    "        winner = np.argmax(coherence_values)\n",
    "        d[x][gen.name] = model_list[winner]\n",
    "        topics.append(model_list[winner].show_topics())\n",
    "        coherence.append(max(coherence_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "women\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/gensim/models/phrases.py:494: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "men\n"
     ]
    }
   ],
   "source": [
    "# run topic modeling for both overall gender scripts \n",
    "# add the results to the dictionary\n",
    "\n",
    "d['overall'] = {}\n",
    "topics2 = []\n",
    "coherence2 = []\n",
    "\n",
    "for gen in [women, men]:\n",
    "    print (gen.name)\n",
    "    words = gen.words\n",
    "    #data_words, id2word, corpus = prep_for_model(gen)\n",
    "    data_words, id2word, corpus = prep_for_model(words)\n",
    "    model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus,\n",
    "                                                        texts=data_words, start=4, limit=11, step=2)\n",
    "    winner = np.argmax(coherence_values)\n",
    "    d['overall'][gen.name] = model_list[winner]\n",
    "    topics2.append(model_list[winner].show_topics())\n",
    "    coherence2.append(max(coherence_values))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.34974983801416842, 0.36282345700250657]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coherence2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0,\n",
       "   '0.071*\"like\" + 0.060*\"want\" + 0.038*\"right\" + 0.027*\"take\" + 0.022*\"okay\" + 0.017*\"leave\" + 0.017*\"love\" + 0.017*\"much\" + 0.016*\"nothing\" + 0.015*\"guy\"'),\n",
       "  (1,\n",
       "   '0.109*\"know\" + 0.068*\"think\" + 0.039*\"come\" + 0.037*\"oh\" + 0.031*\"thing\" + 0.029*\"good\" + 0.028*\"really\" + 0.025*\"would\" + 0.020*\"back\" + 0.011*\"stuff\"'),\n",
       "  (2,\n",
       "   '0.083*\"get\" + 0.050*\"well\" + 0.028*\"yes\" + 0.027*\"yeah\" + 0.023*\"call\" + 0.019*\"let\" + 0.017*\"way\" + 0.017*\"people\" + 0.017*\"believe\" + 0.016*\"god\"'),\n",
       "  (3,\n",
       "   '0.071*\"say\" + 0.049*\"mean\" + 0.042*\"something\" + 0.026*\"happen\" + 0.019*\"life\" + 0.018*\"hear\" + 0.017*\"house\" + 0.013*\"must\" + 0.011*\"man\" + 0.011*\"year\"'),\n",
       "  (4,\n",
       "   '0.080*\"go\" + 0.043*\"look\" + 0.040*\"see\" + 0.033*\"tell\" + 0.031*\"one\" + 0.025*\"talk\" + 0.025*\"could\" + 0.023*\"sure\" + 0.021*\"maybe\" + 0.019*\"try\"'),\n",
       "  (5,\n",
       "   '0.036*\"make\" + 0.034*\"time\" + 0.033*\"never\" + 0.022*\"little\" + 0.019*\"even\" + 0.018*\"feel\" + 0.017*\"sorry\" + 0.017*\"work\" + 0.017*\"find\" + 0.014*\"stop\"')],\n",
       " [(0,\n",
       "   '0.052*\"want\" + 0.037*\"one\" + 0.035*\"come\" + 0.034*\"see\" + 0.031*\"look\" + 0.030*\"yeah\" + 0.023*\"give\" + 0.020*\"let\" + 0.017*\"way\" + 0.015*\"really\"'),\n",
       "  (1,\n",
       "   '0.040*\"yes\" + 0.026*\"sir\" + 0.026*\"rose\" + 0.018*\"leave\" + 0.016*\"harry\" + 0.015*\"still\" + 0.015*\"much\" + 0.015*\"stop\" + 0.014*\"prayer\" + 0.014*\"fuckin\"'),\n",
       "  (2,\n",
       "   '0.073*\"know\" + 0.045*\"like\" + 0.045*\"think\" + 0.025*\"good\" + 0.023*\"would\" + 0.021*\"time\" + 0.020*\"mean\" + 0.018*\"thing\" + 0.017*\"guy\" + 0.014*\"something\"'),\n",
       "  (3,\n",
       "   '0.114*\"get\" + 0.029*\"talk\" + 0.028*\"back\" + 0.024*\"maybe\" + 0.014*\"around\" + 0.011*\"old\" + 0.011*\"always\" + 0.008*\"away\" + 0.008*\"boy\" + 0.008*\"number\"'),\n",
       "  (4,\n",
       "   '0.038*\"take\" + 0.020*\"fuck\" + 0.020*\"call\" + 0.019*\"life\" + 0.018*\"believe\" + 0.018*\"two\" + 0.017*\"okay\" + 0.016*\"ask\" + 0.015*\"nothing\" + 0.015*\"use\"'),\n",
       "  (5,\n",
       "   '0.075*\"go\" + 0.050*\"say\" + 0.040*\"tell\" + 0.039*\"right\" + 0.037*\"well\" + 0.027*\"make\" + 0.021*\"man\" + 0.021*\"could\" + 0.019*\"oh\" + 0.014*\"work\"')]]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'action': {'men': <gensim.models.ldamodel.LdaModel at 0x12374a940>,\n",
       "  'women': <gensim.models.ldamodel.LdaModel at 0x125a3bdd8>},\n",
       " 'comedy': {'men': <gensim.models.ldamodel.LdaModel at 0x12374e4e0>,\n",
       "  'women': <gensim.models.ldamodel.LdaModel at 0x126d657b8>},\n",
       " 'crime': {'men': <gensim.models.ldamodel.LdaModel at 0x102169dd8>,\n",
       "  'women': <gensim.models.ldamodel.LdaModel at 0x12385c940>},\n",
       " 'drama': {'men': <gensim.models.ldamodel.LdaModel at 0x112341470>,\n",
       "  'women': <gensim.models.ldamodel.LdaModel at 0x1235f5278>},\n",
       " 'overall': {'men': <gensim.models.ldamodel.LdaModel at 0x1237da1d0>,\n",
       "  'women': <gensim.models.ldamodel.LdaModel at 0x135162358>}}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# create features for classification\n",
    "# run this on the whole set of movies \n",
    "\n",
    "def topic_features(df, d, common_genres):\n",
    "\n",
    "    # create empty features to be filled\n",
    "    df = pd.concat([df,pd.DataFrame(columns=[\"WT1\", \"WT2\", \"WT3\", \"MT1\", \"MT2\", \"MT3\"])])\n",
    "    df = df[df.gender_from != '?']\n",
    "\n",
    "\n",
    "    for gender in [\"women\", \"men\"]: \n",
    "\n",
    "        # for lines from common genres, get probabilities based on genre-and-gender-specific model\n",
    "        for genre in common_genres:\n",
    "\n",
    "            #subset the data\n",
    "            genre_df = df[df.genre == genre]\n",
    "            genre_df.reset_index(inplace = True)\n",
    "\n",
    "            #select appropriate model \n",
    "            model = d[genre][gender]\n",
    "\n",
    "            #split data into chunks\n",
    "            indices = [x for x in range(0, len(genre_df), 5000)]\n",
    "            indices.append(len(genre_df))\n",
    "            splits = [genre_df.index[indices[i]:indices[i+1]] for i in range(len(indices)-1)]\n",
    "            subsets = [genre_df.iloc[split] for split in splits]\n",
    "\n",
    "            for subset in subsets: \n",
    "                data_words, id2word, corpus = prep_for_model(subset.words)\n",
    "                try: \n",
    "                    gammas = model.inference(corpus)[0]\n",
    "                except IndexError: \n",
    "                    print (\"index error!\")\n",
    "                    print (gender)\n",
    "                    print (genre)\n",
    "                else: \n",
    "                    #select only top 3 topics\n",
    "                    trunc_gammas = [x[:3] for x in gammas]\n",
    "\n",
    "                #add gammas to the dataframe\n",
    "                if gender == \"women\":\n",
    "                    df.loc[subset['index'], ['WT1', 'WT2', \"WT3\"]] = trunc_gammas\n",
    "                if gender == \"men\":\n",
    "                    df.loc[subset['index'], ['MT1', 'MT2', \"MT3\"]] = trunc_gammas\n",
    "                    \n",
    "            #print (genre)\n",
    "            #return df\n",
    "                   \n",
    "            \n",
    "        # for lines from uncommon genres, use probabilities based on gender-specific model\n",
    "        print(\"uncommon!\")\n",
    "        uncommon_genres = df[~df.genre.isin(common_genres)]\n",
    "        uncommon_genres.reset_index(inplace = True)\n",
    "\n",
    "\n",
    "        #choose model \n",
    "        model = d['overall'][gender]\n",
    "        \n",
    "        #get gammas\n",
    "        indices = [x for x in range(0, len(uncommon_genres), 10000)]\n",
    "        indices.append(len(uncommon_genres))\n",
    "        splits = [uncommon_genres.index[indices[i]:indices[i+1]] for i in range(len(indices)-1)]\n",
    "        subsets = [uncommon_genres.iloc[split] for split in splits]\n",
    "        for subset in subsets: \n",
    "            data_words, id2word, corpus = prep_for_model(subset.words)\n",
    "            try: \n",
    "                gammas = model.inference(corpus)[0]\n",
    "            except IndexError: \n",
    "                print (\"index error!\")\n",
    "            else: \n",
    "                trunc_gammas = [x[:3] for x in gammas]\n",
    "\n",
    "            #set gammas\n",
    "            if gender == \"women\":\n",
    "                df.loc[subset['index'], ['WT1', 'WT2', \"WT3\"]] = trunc_gammas\n",
    "            if gender == \"men\":\n",
    "                df.loc[subset['index'], ['MT1', 'MT2', \"MT3\"]] = trunc_gammas\n",
    "                \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/gensim/models/phrases.py:494: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uncommon!\n",
      "uncommon!\n"
     ]
    }
   ],
   "source": [
    "text_all_topics = topic_features(text_all, d, common_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle.dump(text_all_topics, open('../data/movies_lines_train_topics.p', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/gensim/models/phrases.py:494: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uncommon!\n",
      "uncommon!\n"
     ]
    }
   ],
   "source": [
    "#after fixing the male/female models and only getting values for known genders\n",
    "text_all_topics2 = topic_features(text_all, d, common_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#just making features that don't make sense while models are training\n",
    "\n",
    "text_topics = pd.concat([text,pd.DataFrame(columns=[\"WT1\", \"WT2\", \"WT3\", \"MT1\", \"MT2\", \"MT3\"])])\n",
    "text_topics = text_topics[text_topics.gender_to != '?']\n",
    "\n",
    "\n",
    "for gender in [women.name, men.name]: \n",
    "    #choose a model \n",
    "    model = d[\"action\"][gender]\n",
    "    \n",
    "    #get gamma, probability of topics for each row\n",
    "    #indices = [0, 51762, 103524, 155286, len(text_topics)]\n",
    "    indices = [x for x in range(0, len(text_topics), 5000)]\n",
    "    indices.append(len(text_topics))\n",
    "    splits = [text_topics.index[indices[i]:indices[i+1]] for i in range(len(indices)-1)]\n",
    "    subsets = [text_topics.iloc[split] for split in splits]\n",
    "    for subset in subsets: \n",
    "        data_words, id2word, corpus = prep_for_model(subset.words)\n",
    "        try: \n",
    "            gammas = model.inference(corpus)[0]\n",
    "        except IndexError: \n",
    "            print (\"index!\")\n",
    "\n",
    "        else: \n",
    "            print (\"ok!\")\n",
    "            trunc_gammas = [x[:3] for x in gammas]\n",
    "\n",
    "\n",
    "        if gender == \"women\":\n",
    "            text_topics.loc[subset.index, ['WT1', 'WT2', \"WT3\"]] = trunc_gammas\n",
    "        if gender == \"men\":\n",
    "            text_topics.loc[subset.index, ['MT1', 'MT2', \"MT3\"]] = trunc_gammas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(text_topics, open('../data/movies_lines_train_topics.p', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# trying the sklearn version\n",
    "\n",
    "texts = [men.words, women.words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ngram_range = [(1,1), (2,3)] # bag of words, bigrams and trigrams\n",
    "max_features = [1000]\n",
    "no_topics = [8, 10, 15]\n",
    "no_top_words = [5, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print (\"Topic %d:\" % (topic_idx))\n",
    "        print (\" ,\".join([feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
    "        \n",
    "# inspiration source: https://medium.com/mlreview/topic-modeling-with-scikit-learn-e80d33668730"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# only lda                       \n",
    "\n",
    "def topic_model(texts):\n",
    "\n",
    "    for a in ngram_range:\n",
    "        print (a)\n",
    "        for x in max_features:\n",
    "            print (x)\n",
    "            for y in no_topics: \n",
    "                print (y)\n",
    "                for text in texts: \n",
    "\n",
    "                    #transform\n",
    "                    count_vect = CountVectorizer(ngram_range = a, max_features = x, stop_words = 'english') # using bigrams and trigrams\n",
    "                    word_counts = count_vect.fit_transform(text, )\n",
    "                    tfidf_transformer = TfidfTransformer()\n",
    "                    words_tfidf = tfidf_transformer.fit_transform(word_counts)\n",
    "\n",
    "                    lda = LatentDirichletAllocation(n_topics=y, max_iter=5, learning_method='online', learning_offset=50.,random_state=0).fit(word_counts) \n",
    "                        \n",
    "                    for z in no_top_words: \n",
    "                        print (z)\n",
    "                        display_topics(lda, count_vect.get_feature_names(), z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "topic_model(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# transform\n",
    "count_vect = CountVectorizer(ngram_range = (2,3), max_features = 1000, stop_words = 'english') # using bigrams and trigrams\n",
    "w_words_counts = count_vect.fit_transform(women.words, )\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "w_words_tfidf = tfidf_transformer.fit_transform(w_words_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# transform\n",
    "#count_vect2 = CountVectorizer(ngram_range = (2,3)) # using bigrams and trigrams\n",
    "count_vect2 = CountVectorizer(ngram_range = (2,3), max_features = 1000, stop_words = 'english') # using bigrams and trigrams\n",
    "m_words_counts = count_vect2.fit_transform(men.words, )\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "m_words_tfidf = tfidf_transformer.fit_transform(m_words_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "nmf = NMF(n_components=20, random_state=1, alpha=.1, l1_ratio=.5, init='nndsvd').fit(w_words_tfidf)\n",
    "nmf2 = NMF(n_components=20, random_state=1, alpha=.1, l1_ratio=.5, init='nndsvd').fit(m_words_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Run LDA for women\n",
    "lda = LatentDirichletAllocation(n_topics=10, max_iter=5, learning_method='online', learning_offset=50.,random_state=0).fit(w_words_counts) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# LDA for men\n",
    "lda2 = LatentDirichletAllocation(n_topics=10, max_iter=5, learning_method='online', learning_offset=50.,random_state=0).fit(m_words_counts) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "no_top_words = 10\n",
    "display_topics(lda, count_vect.get_feature_names(), no_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "display_topics(lda2, count_vect.get_feature_names(), no_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "no_top_words = 10\n",
    "display_topics(nmf2, count_vect2.get_feature_names(), no_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# count_vect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# words_tfidf[1,:].toarray()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
