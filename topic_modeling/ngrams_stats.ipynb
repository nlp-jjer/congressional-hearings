{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer\n",
    "from sklearn import metrics \n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# print (pd.__name__, pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "text = pd.read_pickle(\"../data/movies_lines_train.p\")\n",
    "text_all = pd.read_pickle(\"../data/movies.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(304354, 9)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender_to</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>gender_from</th>\n",
       "      <th>char_id_from</th>\n",
       "      <th>char_id_to</th>\n",
       "      <th>line_id</th>\n",
       "      <th>words</th>\n",
       "      <th>movie_year</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m</td>\n",
       "      <td>m0</td>\n",
       "      <td>f</td>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>L194</td>\n",
       "      <td>we make quick roxanne korrine andrew barrett i...</td>\n",
       "      <td>1999</td>\n",
       "      <td>comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>m</td>\n",
       "      <td>m0</td>\n",
       "      <td>f</td>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>L195</td>\n",
       "      <td>well i think we start pronunciation okay you</td>\n",
       "      <td>1999</td>\n",
       "      <td>comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>m</td>\n",
       "      <td>m0</td>\n",
       "      <td>f</td>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>L196</td>\n",
       "      <td>hacking gagging spit part please</td>\n",
       "      <td>1999</td>\n",
       "      <td>comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>m</td>\n",
       "      <td>m0</td>\n",
       "      <td>f</td>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>L197</td>\n",
       "      <td>okay bout we try french cuisine saturday night</td>\n",
       "      <td>1999</td>\n",
       "      <td>comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>m</td>\n",
       "      <td>m0</td>\n",
       "      <td>f</td>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>L198</td>\n",
       "      <td>you ask me cute your name</td>\n",
       "      <td>1999</td>\n",
       "      <td>comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender_to movie_id gender_from char_id_from char_id_to line_id  \\\n",
       "0         m       m0           f           u0         u2    L194   \n",
       "1         m       m0           f           u0         u2    L195   \n",
       "2         m       m0           f           u0         u2    L196   \n",
       "3         m       m0           f           u0         u2    L197   \n",
       "4         m       m0           f           u0         u2    L198   \n",
       "\n",
       "                                               words movie_year   genre  \n",
       "0  we make quick roxanne korrine andrew barrett i...       1999  comedy  \n",
       "1       well i think we start pronunciation okay you       1999  comedy  \n",
       "2                   hacking gagging spit part please       1999  comedy  \n",
       "3     okay bout we try french cuisine saturday night       1999  comedy  \n",
       "4                          you ask me cute your name       1999  comedy  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Common n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def grams_df(df, numgrams):\n",
    "\n",
    "    grams_df = pd.DataFrame({'grams': [], 'line_id': []})\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        #print(index)\n",
    "        #create list of bigrams for each text\n",
    "        text = row['words']    \n",
    "        token = nltk.word_tokenize(text)\n",
    "        grams_list = list(ngrams(token, numgrams))\n",
    "        #grams_list = [gram for gram in grams]\n",
    "\n",
    "        #create dict of ngrams\n",
    "        line = row['line_id']\n",
    "        gen = row['gender_from']\n",
    "        d = {'grams': grams_list, 'line_id': np.repeat(line, len(grams_list)), 'gender_from': np.repeat(gen, len(grams_list))}\n",
    "        grams_df = pd.concat([grams_df, pd.DataFrame(d)], axis = 0)\n",
    "        \n",
    "    return grams_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test = text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "grams_df = grams_df(test,3)\n",
    "grams_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "bigrams = grams_df(text[:10000],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "bigrams = grams_df(text[:50000],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "bigrams['grams'].value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# remove unknown gender\n",
    "bigrams = bigrams[bigrams['gender_from'] != '?']\n",
    "\n",
    "# get counts\n",
    "grouped = bigrams.groupby(['gender_from', 'grams']).count()\n",
    "g = grouped['line_id'].groupby(level=0, group_keys=False).apply(lambda x: x.sort_values(ascending=False).head(10))\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "bigrams_genre = pd.merge(bigrams, text[['genre', 'line_id']], on = 'line_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "bigrams_genre.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "grouped2 = bigrams_genre.groupby(['genre','gender_from', 'grams']).count()\n",
    "g2 = grouped2['line_id'].groupby(['genre', 'gender_from'], group_keys=False).apply(lambda x: x.sort_values(ascending=False).head(5))\n",
    "g2.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Topic Modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#mallet_path = '/Users/jasmindial/Desktop/mallet-2.0.8/bin/mallet'\n",
    "mallet_path = \"../mallet-2.0.8/bin/mallet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# remove terms with low frequency\n",
    "\n",
    "# get all the words\n",
    "total = []\n",
    "for index, row in text.iterrows():\n",
    "    Text = row['words']    \n",
    "    token = nltk.word_tokenize(Text)\n",
    "    total.extend(token) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "high_freq = nltk.FreqDist(total).most_common(round(.9*text.shape[0]))\n",
    "high_freq = [word for (word, count) in high_freq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_words(x):\n",
    "\n",
    "    tags = ['IN', 'CD', 'MD']\n",
    "    text = nltk.word_tokenize(x)\n",
    "    tags = nltk.pos_tag(text)\n",
    "    \n",
    "    # remove non-meaningful POS & very low-frequency\n",
    "    words = [word for (word, tag) in tags if tag not in tags if word in high_freq]\n",
    "    \n",
    "    return words\n",
    "\n",
    "text['words'] = text['words'].apply(clean_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# get two separate texts \n",
    "women = text[text['gender_from'] == 'f']\n",
    "women.name = 'women'\n",
    "men = text[text['gender_from'] == 'm']\n",
    "men.name = 'men'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51762, 9)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "women.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125707, 9)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "men.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "stopWords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# source: https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/\n",
    "# trying the genism version "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def add_ngrams(texts):\n",
    "    \n",
    "    bigram = gensim.models.Phrases(texts, common_terms=stopWords, min_count=5, threshold=25) \n",
    "    trigram = gensim.models.Phrases(bigram[texts], threshold=25)  \n",
    "\n",
    "    bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "    trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "    \n",
    "    texts = [[word for word in simple_preprocess(str(doc)) if word not in stopWords] for doc in texts]\n",
    "    texts = [bigram_mod[doc] for doc in texts]\n",
    "    texts = [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "    \n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def prep_for_model(series):\n",
    "    \n",
    "    # convert to list\n",
    "    data = series.values.tolist()\n",
    "\n",
    "    # tokenize \n",
    "    def sent_to_words(sentences):\n",
    "        for sentence in sentences:\n",
    "            yield(gensim.utils.simple_preprocess(str(sentence)))  \n",
    "\n",
    "    data_words = list(sent_to_words(data)) \n",
    "    data_words = add_ngrams(data_words)\n",
    "    \n",
    "    # create dictionary\n",
    "    id2word = corpora.Dictionary(data_words)\n",
    "\n",
    "    # Term Document Frequency\n",
    "    corpus = [id2word.doc2bow(text) for text in data_words]\n",
    "    \n",
    "    return data_words, id2word, corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/gensim/models/phrases.py:494: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "223"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just testing \n",
    "data_words, id2word, corpus = prep_for_model(women.words)\n",
    "# make sure grams are working\n",
    "len(set([word for sent in data_words for word in sent if \"_\" in word]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# doesn't like this\n",
    "#lda_model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=8, id2word=id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        #print (num_topics)\n",
    "        lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,id2word=id2word, num_topics=num_topics, \n",
    "                                                    random_state=100, update_every=1, chunksize=100, passes=10,\n",
    "                                                    alpha='auto', per_word_topics=True)\n",
    "        #lda_model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=id2word)\n",
    "        model_list.append(lda_model)\n",
    "        coherencemodel = CoherenceModel(model=lda_model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# run models and get coherence values\n",
    "# model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus,\n",
    "                                                        #texts=data_words, start=3, limit=13, step=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "women\n",
      "(7808, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/gensim/models/phrases.py:494: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11905, 9)\n",
      "(14644, 9)\n",
      "(6612, 9)\n",
      "men\n",
      "(29431, 9)\n",
      "(28995, 9)\n",
      "(28992, 9)\n",
      "(15973, 9)\n"
     ]
    }
   ],
   "source": [
    "# run topic modeling for both gender scripts \n",
    "# this takes a while :)\n",
    "\n",
    "common_genres = [\"action\", \"drama\", \"comedy\", \"crime\"]\n",
    "#dictionary of models\n",
    "d = {genre:{} for genre in common_genres}\n",
    "\n",
    "topics = []\n",
    "coherence = []\n",
    "\n",
    "for gen in [women, men]:\n",
    "    print (gen.name)\n",
    "    for x in common_genres:\n",
    "        df = gen[gen.genre == x]\n",
    "        print(df.shape)\n",
    "        group = df.words\n",
    "    \n",
    "        data_words, id2word, corpus = prep_for_model(group)\n",
    "        model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus,\n",
    "                                                            texts=data_words, start=4, limit=13, step=2)\n",
    "        winner = np.argmax(coherence_values)\n",
    "        d[x][gen.name] = model_list[winner]\n",
    "        topics.append(model_list[winner].show_topics())\n",
    "        coherence.append(max(coherence_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "women\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/gensim/models/phrases.py:494: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "men\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-da295e1d0b1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mdata_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid2word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprep_for_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus,\n\u001b[0;32m---> 13\u001b[0;31m                                                         texts=data_words, start=4, limit=13, step=2)\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mwinner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoherence_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'overall'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwinner\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-bc356d186b33>\u001b[0m in \u001b[0;36mcompute_coherence_values\u001b[0;34m(dictionary, corpus, texts, limit, start, step)\u001b[0m\n\u001b[1;32m      7\u001b[0m         lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,id2word=id2word, num_topics=num_topics, \n\u001b[1;32m      8\u001b[0m                                                     \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                                                     alpha='auto', per_word_topics=True)\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;31m#lda_model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=id2word)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mmodel_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlda_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, corpus, num_topics, id2word, distributed, chunksize, passes, update_every, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, minimum_probability, random_state, ns_conf, minimum_phi_value, per_word_topics, callbacks, dtype)\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m             \u001b[0muse_numpy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatcher\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunks_as_numpy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_numpy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minit_dir_prior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, corpus, chunksize, decay, offset, passes, update_every, eval_every, iterations, gamma_threshold, chunks_as_numpy)\u001b[0m\n\u001b[1;32m    718\u001b[0m                         \u001b[0mpass_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_no\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlencorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m                     )\n\u001b[0;32m--> 720\u001b[0;31m                     \u001b[0mgammat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_estep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize_alpha\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36mdo_estep\u001b[0;34m(self, chunk, state)\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m         \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollect_sstats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m         \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msstats\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msstats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumdocs\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# avoids calling len(chunk) on a generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36minference\u001b[0;34m(self, chunk, collect_sstats)\u001b[0m\n\u001b[1;32m    494\u001b[0m                 \u001b[0;31m# the update for gamma gives this update. Cf. Lee&Seung 2001.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m                 \u001b[0mgammad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mexpElogthetad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcts\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mphinorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpElogbetad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m                 \u001b[0mElogthetad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdirichlet_expectation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgammad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m                 \u001b[0mexpElogthetad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mElogthetad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                 \u001b[0mphinorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpElogthetad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpElogbetad\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# run topic modeling for both overall gender scripts \n",
    "# add the results to the dictionary\n",
    "\n",
    "d['overall'] = {}\n",
    "topics2 = []\n",
    "coherence2 = []\n",
    "\n",
    "for gen in [women, men]:\n",
    "    print (gen.name)\n",
    "    words = gen.words\n",
    "    data_words, id2word, corpus = prep_for_model(gen)\n",
    "    model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus,\n",
    "                                                        texts=data_words, start=4, limit=13, step=2)\n",
    "    winner = np.argmax(coherence_values)\n",
    "    d['overall'][gen.name] = model_list[winner]\n",
    "    topics2.append(model_list[winner].show_topics())\n",
    "    coherence2.append(max(coherence_values))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'action': {'men': <gensim.models.ldamodel.LdaModel at 0x12374a940>,\n",
       "  'women': <gensim.models.ldamodel.LdaModel at 0x125a3bdd8>},\n",
       " 'comedy': {'men': <gensim.models.ldamodel.LdaModel at 0x12374e4e0>,\n",
       "  'women': <gensim.models.ldamodel.LdaModel at 0x126d657b8>},\n",
       " 'crime': {'men': <gensim.models.ldamodel.LdaModel at 0x102169dd8>,\n",
       "  'women': <gensim.models.ldamodel.LdaModel at 0x12385c940>},\n",
       " 'drama': {'men': <gensim.models.ldamodel.LdaModel at 0x112341470>,\n",
       "  'women': <gensim.models.ldamodel.LdaModel at 0x1235f5278>},\n",
       " 'overall': {'women': <gensim.models.ldamodel.LdaModel at 0x10d813828>}}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# create features for classification\n",
    "# run this on the whole set of movies \n",
    "\n",
    "def topic_features(df, d, common_genres):\n",
    "\n",
    "    # create empty features to be filled\n",
    "    df = pd.concat([df,pd.DataFrame(columns=[\"WT1\", \"WT2\", \"WT3\", \"MT1\", \"MT2\", \"MT3\"])])\n",
    "    df_mf = df[df.gender_from != '?']\n",
    "\n",
    "\n",
    "    for gender in [\"women\", \"men\"]: \n",
    "\n",
    "        # for lines from common genres, get probabilities based on genre-and-gender-specific model\n",
    "        for genre in common_genres:\n",
    "\n",
    "            #subset the data\n",
    "            genre_df = df[df.genre == genre]\n",
    "            genre_df.reset_index(inplace = True)\n",
    "\n",
    "            #select appropriate model \n",
    "            model = d[genre][gender]\n",
    "\n",
    "            #split data into chunks\n",
    "            indices = [x for x in range(0, len(genre_df), 6611)]\n",
    "            indices.append(len(genre_df))\n",
    "            splits = [genre_df.index[indices[i]:indices[i+1]] for i in range(len(indices)-1)]\n",
    "            subsets = [genre_df.iloc[split] for split in splits]\n",
    "\n",
    "            for subset in subsets: \n",
    "                data_words, id2word, corpus = prep_for_model(subset.words)\n",
    "                try: \n",
    "                    gammas = model.inference(corpus)[0]\n",
    "                except IndexError: \n",
    "                    print (\"index error!\")\n",
    "                else: \n",
    "                    print (\"ok!\")\n",
    "                    #select only top 3 topics\n",
    "                    trunc_gammas = [x[:3] for x in gammas]\n",
    "\n",
    "                #add gammas to the dataframe\n",
    "                if gender == \"women\":\n",
    "                    df.loc[subset['index'], ['WT1', 'WT2', \"WT3\"]] = trunc_gammas\n",
    "                if gender == \"men\":\n",
    "                    df.loc[subset['index'], ['MT1', 'MT2', \"MT3\"]] = trunc_gammas\n",
    "                    \n",
    "            #print (genre)\n",
    "            return df\n",
    "        \"\"\"            \n",
    "        # for lines from uncommon genres, use probabilities based on gender-specific model\n",
    "\n",
    "        uncommon_genres = text_topics[text_topics.genre not in common_genres]\n",
    "\n",
    "        #choose model \n",
    "        model = d['overall'][gender]\n",
    "        gammas = model.inference(uncommon_genres)\n",
    "        if gender == \"women\":\n",
    "            text_topics.loc[text_topics.genre not in common_genres, ['WT1', 'WT2', \"WT3\"]] = gammas\n",
    "        if gender == \"men\":\n",
    "            text_topics.loc[text_topics.genre not in common_genres, ['MT1', 'MT2', \"MT3\"]] = gammas\n",
    "        \"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/gensim/models/phrases.py:494: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "action\n"
     ]
    }
   ],
   "source": [
    "topic_features(text_all, d, common_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/gensim/models/phrases.py:494: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n",
      "ok!\n"
     ]
    }
   ],
   "source": [
    "#just making features that don't make sense\n",
    "\n",
    "text_topics = pd.concat([text,pd.DataFrame(columns=[\"WT1\", \"WT2\", \"WT3\", \"MT1\", \"MT2\", \"MT3\"])])\n",
    "text_topics = text_topics[text_topics.gender_to != '?']\n",
    "\n",
    "\n",
    "for gender in [women.name, men.name]: \n",
    "    #choose a model \n",
    "    model = d[\"action\"][gender]\n",
    "    \n",
    "    #get gamma, probability of topics for each row\n",
    "    #indices = [0, 51762, 103524, 155286, len(text_topics)]\n",
    "    indices = [x for x in range(0, len(text_topics), 5000)]\n",
    "    indices.append(len(text_topics))\n",
    "    splits = [text_topics.index[indices[i]:indices[i+1]] for i in range(len(indices)-1)]\n",
    "    subsets = [text_topics.iloc[split] for split in splits]\n",
    "    for subset in subsets: \n",
    "        data_words, id2word, corpus = prep_for_model(subset.words)\n",
    "        try: \n",
    "            gammas = model.inference(corpus)[0]\n",
    "        except IndexError: \n",
    "            print (\"index!\")\n",
    "\n",
    "        else: \n",
    "            print (\"ok!\")\n",
    "            trunc_gammas = [x[:3] for x in gammas]\n",
    "\n",
    "\n",
    "        if gender == \"women\":\n",
    "            text_topics.loc[subset.index, ['WT1', 'WT2', \"WT3\"]] = trunc_gammas\n",
    "        if gender == \"men\":\n",
    "            text_topics.loc[subset.index, ['MT1', 'MT2', \"MT3\"]] = trunc_gammas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(text_topics, open('../data/movies_lines_train_topics.p', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(202394, 15)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_topics.shape\n",
    "[s[indices[i]:indices[i+1]] for i in xrange(len(indices)-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "splits = [0, 51762, 103524, 155286, len(text_topics)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "testing = [text_topics.index[splits[i]:splits[i+1]] for i in range(len(splits)-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MT1</th>\n",
       "      <th>MT2</th>\n",
       "      <th>MT3</th>\n",
       "      <th>WT1</th>\n",
       "      <th>WT2</th>\n",
       "      <th>WT3</th>\n",
       "      <th>char_id_from</th>\n",
       "      <th>char_id_to</th>\n",
       "      <th>gender_from</th>\n",
       "      <th>gender_to</th>\n",
       "      <th>genre</th>\n",
       "      <th>line_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>movie_year</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51762</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u8830</td>\n",
       "      <td>u8843</td>\n",
       "      <td>m</td>\n",
       "      <td>f</td>\n",
       "      <td>crime</td>\n",
       "      <td>L645156</td>\n",
       "      <td>m599</td>\n",
       "      <td>1987</td>\n",
       "      <td>okay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51763</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u8830</td>\n",
       "      <td>u8843</td>\n",
       "      <td>m</td>\n",
       "      <td>f</td>\n",
       "      <td>crime</td>\n",
       "      <td>L645157</td>\n",
       "      <td>m599</td>\n",
       "      <td>1987</td>\n",
       "      <td>you i hear you guy handle fairchild food merge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51764</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u8830</td>\n",
       "      <td>u8843</td>\n",
       "      <td>m</td>\n",
       "      <td>f</td>\n",
       "      <td>crime</td>\n",
       "      <td>L645158</td>\n",
       "      <td>m599</td>\n",
       "      <td>1987</td>\n",
       "      <td>come buddy you want get me disbar would you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51765</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u8830</td>\n",
       "      <td>u8843</td>\n",
       "      <td>m</td>\n",
       "      <td>f</td>\n",
       "      <td>crime</td>\n",
       "      <td>L645159</td>\n",
       "      <td>m599</td>\n",
       "      <td>1987</td>\n",
       "      <td>listen it one college buddy talk another</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51766</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u8830</td>\n",
       "      <td>u8843</td>\n",
       "      <td>m</td>\n",
       "      <td>f</td>\n",
       "      <td>crime</td>\n",
       "      <td>L645160</td>\n",
       "      <td>m599</td>\n",
       "      <td>1987</td>\n",
       "      <td>yeah right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51767</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u8830</td>\n",
       "      <td>u8843</td>\n",
       "      <td>m</td>\n",
       "      <td>f</td>\n",
       "      <td>crime</td>\n",
       "      <td>L645161</td>\n",
       "      <td>m599</td>\n",
       "      <td>1987</td>\n",
       "      <td>relax roger everybody it you know you know</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51768</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u8830</td>\n",
       "      <td>u8843</td>\n",
       "      <td>m</td>\n",
       "      <td>f</td>\n",
       "      <td>crime</td>\n",
       "      <td>L645162</td>\n",
       "      <td>m599</td>\n",
       "      <td>1987</td>\n",
       "      <td>i it moi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51769</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u8830</td>\n",
       "      <td>u8843</td>\n",
       "      <td>m</td>\n",
       "      <td>f</td>\n",
       "      <td>crime</td>\n",
       "      <td>L645163</td>\n",
       "      <td>m599</td>\n",
       "      <td>1987</td>\n",
       "      <td>money you ever dream roger thing one get hurt ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51770</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u8830</td>\n",
       "      <td>u8843</td>\n",
       "      <td>m</td>\n",
       "      <td>f</td>\n",
       "      <td>crime</td>\n",
       "      <td>L645164</td>\n",
       "      <td>m599</td>\n",
       "      <td>1987</td>\n",
       "      <td>much i walk you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51771</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u8830</td>\n",
       "      <td>u8843</td>\n",
       "      <td>m</td>\n",
       "      <td>f</td>\n",
       "      <td>crime</td>\n",
       "      <td>L645253</td>\n",
       "      <td>m599</td>\n",
       "      <td>1987</td>\n",
       "      <td>you put dime roger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51772</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u8830</td>\n",
       "      <td>u8843</td>\n",
       "      <td>m</td>\n",
       "      <td>f</td>\n",
       "      <td>crime</td>\n",
       "      <td>L645254</td>\n",
       "      <td>m599</td>\n",
       "      <td>1987</td>\n",
       "      <td>right bud let it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51773</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u8830</td>\n",
       "      <td>u8843</td>\n",
       "      <td>m</td>\n",
       "      <td>f</td>\n",
       "      <td>crime</td>\n",
       "      <td>L645356</td>\n",
       "      <td>m599</td>\n",
       "      <td>1987</td>\n",
       "      <td>problem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51774</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u8830</td>\n",
       "      <td>u8843</td>\n",
       "      <td>m</td>\n",
       "      <td>f</td>\n",
       "      <td>crime</td>\n",
       "      <td>L645357</td>\n",
       "      <td>m599</td>\n",
       "      <td>1987</td>\n",
       "      <td>get strange call sec they ask see my record bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51775</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u8830</td>\n",
       "      <td>u8843</td>\n",
       "      <td>m</td>\n",
       "      <td>f</td>\n",
       "      <td>crime</td>\n",
       "      <td>L645358</td>\n",
       "      <td>m599</td>\n",
       "      <td>1987</td>\n",
       "      <td>relax roget you 82m account number i invisible...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51776</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u8830</td>\n",
       "      <td>u8843</td>\n",
       "      <td>m</td>\n",
       "      <td>f</td>\n",
       "      <td>crime</td>\n",
       "      <td>L645359</td>\n",
       "      <td>m599</td>\n",
       "      <td>1987</td>\n",
       "      <td>alright i wanna slow bud call awhile lunch we ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51777</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u8830</td>\n",
       "      <td>u8843</td>\n",
       "      <td>m</td>\n",
       "      <td>f</td>\n",
       "      <td>crime</td>\n",
       "      <td>L645360</td>\n",
       "      <td>m599</td>\n",
       "      <td>1987</td>\n",
       "      <td>sure roger whatever you want it cool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51778</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u8830</td>\n",
       "      <td>u8843</td>\n",
       "      <td>m</td>\n",
       "      <td>f</td>\n",
       "      <td>crime</td>\n",
       "      <td>L645362</td>\n",
       "      <td>m599</td>\n",
       "      <td>1987</td>\n",
       "      <td>gekko ask u bluestar deal we review timetable ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51779</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u8830</td>\n",
       "      <td>u8843</td>\n",
       "      <td>m</td>\n",
       "      <td>f</td>\n",
       "      <td>crime</td>\n",
       "      <td>L645363</td>\n",
       "      <td>m599</td>\n",
       "      <td>1987</td>\n",
       "      <td>he never tell me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51780</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u8830</td>\n",
       "      <td>u8843</td>\n",
       "      <td>m</td>\n",
       "      <td>f</td>\n",
       "      <td>crime</td>\n",
       "      <td>L645364</td>\n",
       "      <td>m599</td>\n",
       "      <td>1987</td>\n",
       "      <td>you president company you know come</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51781</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u8836</td>\n",
       "      <td>u8844</td>\n",
       "      <td>m</td>\n",
       "      <td>?</td>\n",
       "      <td>crime</td>\n",
       "      <td>L645125</td>\n",
       "      <td>m599</td>\n",
       "      <td>1987</td>\n",
       "      <td>rare pistol world larry 45 luger six ever manu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51782</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u8836</td>\n",
       "      <td>u8844</td>\n",
       "      <td>m</td>\n",
       "      <td>?</td>\n",
       "      <td>crime</td>\n",
       "      <td>L645126</td>\n",
       "      <td>m599</td>\n",
       "      <td>1987</td>\n",
       "      <td>congratulation rare still your interest anacot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51783</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u8836</td>\n",
       "      <td>u8844</td>\n",
       "      <td>m</td>\n",
       "      <td>?</td>\n",
       "      <td>crime</td>\n",
       "      <td>L645127</td>\n",
       "      <td>m599</td>\n",
       "      <td>1987</td>\n",
       "      <td>interest yours larry money i think it good inv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51784</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u8836</td>\n",
       "      <td>u8844</td>\n",
       "      <td>m</td>\n",
       "      <td>?</td>\n",
       "      <td>crime</td>\n",
       "      <td>L645128</td>\n",
       "      <td>m599</td>\n",
       "      <td>1987</td>\n",
       "      <td>time i long term liquidation gordon i go turn ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51785</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u8836</td>\n",
       "      <td>u8844</td>\n",
       "      <td>m</td>\n",
       "      <td>?</td>\n",
       "      <td>crime</td>\n",
       "      <td>L645129</td>\n",
       "      <td>m599</td>\n",
       "      <td>1987</td>\n",
       "      <td>you must wear mask you laugh hard behind it la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51786</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u8836</td>\n",
       "      <td>u8844</td>\n",
       "      <td>m</td>\n",
       "      <td>?</td>\n",
       "      <td>crime</td>\n",
       "      <td>L645130</td>\n",
       "      <td>m599</td>\n",
       "      <td>1987</td>\n",
       "      <td>i could break you mate two piece my knee you k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51787</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u8836</td>\n",
       "      <td>u8844</td>\n",
       "      <td>m</td>\n",
       "      <td>?</td>\n",
       "      <td>crime</td>\n",
       "      <td>L645137</td>\n",
       "      <td>m599</td>\n",
       "      <td>1987</td>\n",
       "      <td>consider you bring my mother it 71 50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51788</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u8836</td>\n",
       "      <td>u8844</td>\n",
       "      <td>m</td>\n",
       "      <td>?</td>\n",
       "      <td>crime</td>\n",
       "      <td>L645138</td>\n",
       "      <td>m599</td>\n",
       "      <td>1987</td>\n",
       "      <td>done you hear my lawyer 8 good night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51789</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u8836</td>\n",
       "      <td>u8845</td>\n",
       "      <td>m</td>\n",
       "      <td>?</td>\n",
       "      <td>crime</td>\n",
       "      <td>L645300</td>\n",
       "      <td>m599</td>\n",
       "      <td>1987</td>\n",
       "      <td>due respect mr gekko prevent you thing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51790</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u8836</td>\n",
       "      <td>u8845</td>\n",
       "      <td>m</td>\n",
       "      <td>?</td>\n",
       "      <td>crime</td>\n",
       "      <td>L645301</td>\n",
       "      <td>m599</td>\n",
       "      <td>1987</td>\n",
       "      <td>cause i way around way we make money make airl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51791</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u8836</td>\n",
       "      <td>u8845</td>\n",
       "      <td>m</td>\n",
       "      <td>?</td>\n",
       "      <td>crime</td>\n",
       "      <td>L645305</td>\n",
       "      <td>m599</td>\n",
       "      <td>1987</td>\n",
       "      <td>you prepare put writing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103494</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u7005</td>\n",
       "      <td>u7013</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>action</td>\n",
       "      <td>L438133</td>\n",
       "      <td>m468</td>\n",
       "      <td>2001</td>\n",
       "      <td>we fail lose our carrier we destroy our abilit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103495</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u7009</td>\n",
       "      <td>u7013</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>action</td>\n",
       "      <td>L437710</td>\n",
       "      <td>m468</td>\n",
       "      <td>2001</td>\n",
       "      <td>you join u admiral u think your education amer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103496</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u7009</td>\n",
       "      <td>u7013</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>action</td>\n",
       "      <td>L437711</td>\n",
       "      <td>m468</td>\n",
       "      <td>2001</td>\n",
       "      <td>knowledge opponent careful calculation danger ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103497</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u7009</td>\n",
       "      <td>u7013</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>action</td>\n",
       "      <td>L437712</td>\n",
       "      <td>m468</td>\n",
       "      <td>2001</td>\n",
       "      <td>time come strike sit let american cut our oil ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103498</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u7009</td>\n",
       "      <td>u7013</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>action</td>\n",
       "      <td>L437714</td>\n",
       "      <td>m468</td>\n",
       "      <td>2001</td>\n",
       "      <td>you something say yamamoto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103499</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u7009</td>\n",
       "      <td>u7013</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>action</td>\n",
       "      <td>L437715</td>\n",
       "      <td>m468</td>\n",
       "      <td>2001</td>\n",
       "      <td>council know i oppose fight american matter gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103500</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u7009</td>\n",
       "      <td>u7013</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>action</td>\n",
       "      <td>L437716</td>\n",
       "      <td>m468</td>\n",
       "      <td>2001</td>\n",
       "      <td>you see u capable blow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103501</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u7009</td>\n",
       "      <td>u7013</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>action</td>\n",
       "      <td>L437717</td>\n",
       "      <td>m468</td>\n",
       "      <td>2001</td>\n",
       "      <td>american themselves make it possible we annihi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103502</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u2443</td>\n",
       "      <td>u2448</td>\n",
       "      <td>f</td>\n",
       "      <td>m</td>\n",
       "      <td>action</td>\n",
       "      <td>L436413</td>\n",
       "      <td>m157</td>\n",
       "      <td>2000</td>\n",
       "      <td>i know you gabriel marion last time i saw you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103503</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u2443</td>\n",
       "      <td>u2448</td>\n",
       "      <td>f</td>\n",
       "      <td>m</td>\n",
       "      <td>action</td>\n",
       "      <td>L436414</td>\n",
       "      <td>m157</td>\n",
       "      <td>2000</td>\n",
       "      <td>i uh me it samuel i mean nathan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103504</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u2443</td>\n",
       "      <td>u2448</td>\n",
       "      <td>f</td>\n",
       "      <td>m</td>\n",
       "      <td>action</td>\n",
       "      <td>L436415</td>\n",
       "      <td>m157</td>\n",
       "      <td>2000</td>\n",
       "      <td>it you it turn my teeth black month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103505</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u2443</td>\n",
       "      <td>u2448</td>\n",
       "      <td>f</td>\n",
       "      <td>m</td>\n",
       "      <td>action</td>\n",
       "      <td>L436416</td>\n",
       "      <td>m157</td>\n",
       "      <td>2000</td>\n",
       "      <td>uh uh i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103506</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u2443</td>\n",
       "      <td>u2448</td>\n",
       "      <td>f</td>\n",
       "      <td>m</td>\n",
       "      <td>action</td>\n",
       "      <td>L436422</td>\n",
       "      <td>m157</td>\n",
       "      <td>2000</td>\n",
       "      <td>i know you go look like i never would put ink ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103507</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u2443</td>\n",
       "      <td>u2448</td>\n",
       "      <td>f</td>\n",
       "      <td>m</td>\n",
       "      <td>action</td>\n",
       "      <td>L436423</td>\n",
       "      <td>m157</td>\n",
       "      <td>2000</td>\n",
       "      <td>you call compliment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103508</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u2443</td>\n",
       "      <td>u2448</td>\n",
       "      <td>f</td>\n",
       "      <td>m</td>\n",
       "      <td>action</td>\n",
       "      <td>L436424</td>\n",
       "      <td>m157</td>\n",
       "      <td>2000</td>\n",
       "      <td>it start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103509</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u2443</td>\n",
       "      <td>u2448</td>\n",
       "      <td>f</td>\n",
       "      <td>m</td>\n",
       "      <td>action</td>\n",
       "      <td>L436465</td>\n",
       "      <td>m157</td>\n",
       "      <td>2000</td>\n",
       "      <td>next time we bring blanket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103510</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u2443</td>\n",
       "      <td>u2448</td>\n",
       "      <td>f</td>\n",
       "      <td>m</td>\n",
       "      <td>action</td>\n",
       "      <td>L436466</td>\n",
       "      <td>m157</td>\n",
       "      <td>2000</td>\n",
       "      <td>would nice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103511</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u2443</td>\n",
       "      <td>u2448</td>\n",
       "      <td>f</td>\n",
       "      <td>m</td>\n",
       "      <td>action</td>\n",
       "      <td>L436467</td>\n",
       "      <td>m157</td>\n",
       "      <td>2000</td>\n",
       "      <td>maybe we lucky winter rain snow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103512</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u2443</td>\n",
       "      <td>u2448</td>\n",
       "      <td>f</td>\n",
       "      <td>m</td>\n",
       "      <td>action</td>\n",
       "      <td>L436468</td>\n",
       "      <td>m157</td>\n",
       "      <td>2000</td>\n",
       "      <td>would nice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103513</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u2444</td>\n",
       "      <td>u2448</td>\n",
       "      <td>?</td>\n",
       "      <td>m</td>\n",
       "      <td>action</td>\n",
       "      <td>L436364</td>\n",
       "      <td>m157</td>\n",
       "      <td>2000</td>\n",
       "      <td>he make light redcoat kill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103514</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u2444</td>\n",
       "      <td>u2448</td>\n",
       "      <td>?</td>\n",
       "      <td>m</td>\n",
       "      <td>action</td>\n",
       "      <td>L436365</td>\n",
       "      <td>m157</td>\n",
       "      <td>2000</td>\n",
       "      <td>he make light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103515</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u2444</td>\n",
       "      <td>u2448</td>\n",
       "      <td>?</td>\n",
       "      <td>m</td>\n",
       "      <td>action</td>\n",
       "      <td>L436366</td>\n",
       "      <td>m157</td>\n",
       "      <td>2000</td>\n",
       "      <td>you know him well you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103516</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u2444</td>\n",
       "      <td>u2448</td>\n",
       "      <td>?</td>\n",
       "      <td>m</td>\n",
       "      <td>action</td>\n",
       "      <td>L436367</td>\n",
       "      <td>m157</td>\n",
       "      <td>2000</td>\n",
       "      <td>he my father</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103517</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u2444</td>\n",
       "      <td>u2448</td>\n",
       "      <td>?</td>\n",
       "      <td>m</td>\n",
       "      <td>action</td>\n",
       "      <td>L436368</td>\n",
       "      <td>m157</td>\n",
       "      <td>2000</td>\n",
       "      <td>i know him well enough</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103518</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u2444</td>\n",
       "      <td>u2448</td>\n",
       "      <td>?</td>\n",
       "      <td>m</td>\n",
       "      <td>action</td>\n",
       "      <td>L436369</td>\n",
       "      <td>m157</td>\n",
       "      <td>2000</td>\n",
       "      <td>fault him grow frontier it hard time hard plac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103519</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u2444</td>\n",
       "      <td>u2448</td>\n",
       "      <td>?</td>\n",
       "      <td>m</td>\n",
       "      <td>action</td>\n",
       "      <td>L436435</td>\n",
       "      <td>m157</td>\n",
       "      <td>2000</td>\n",
       "      <td>you get salt last week</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103520</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u2444</td>\n",
       "      <td>u2448</td>\n",
       "      <td>?</td>\n",
       "      <td>m</td>\n",
       "      <td>action</td>\n",
       "      <td>L436436</td>\n",
       "      <td>m157</td>\n",
       "      <td>2000</td>\n",
       "      <td>oh right bake powder we need bake powder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103521</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u2444</td>\n",
       "      <td>u2448</td>\n",
       "      <td>?</td>\n",
       "      <td>m</td>\n",
       "      <td>action</td>\n",
       "      <td>L436437</td>\n",
       "      <td>m157</td>\n",
       "      <td>2000</td>\n",
       "      <td>we get plenty bake powder you go pembroke get ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103522</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u2443</td>\n",
       "      <td>u2452</td>\n",
       "      <td>f</td>\n",
       "      <td>m</td>\n",
       "      <td>action</td>\n",
       "      <td>L436586</td>\n",
       "      <td>m157</td>\n",
       "      <td>2000</td>\n",
       "      <td>i sorry we give you warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103523</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u2443</td>\n",
       "      <td>u2452</td>\n",
       "      <td>f</td>\n",
       "      <td>m</td>\n",
       "      <td>action</td>\n",
       "      <td>L436587</td>\n",
       "      <td>m157</td>\n",
       "      <td>2000</td>\n",
       "      <td>it alright i happy you</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51762 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        MT1  MT2  MT3  WT1  WT2  WT3 char_id_from char_id_to gender_from  \\\n",
       "51762   NaN  NaN  NaN  NaN  NaN  NaN        u8830      u8843           m   \n",
       "51763   NaN  NaN  NaN  NaN  NaN  NaN        u8830      u8843           m   \n",
       "51764   NaN  NaN  NaN  NaN  NaN  NaN        u8830      u8843           m   \n",
       "51765   NaN  NaN  NaN  NaN  NaN  NaN        u8830      u8843           m   \n",
       "51766   NaN  NaN  NaN  NaN  NaN  NaN        u8830      u8843           m   \n",
       "51767   NaN  NaN  NaN  NaN  NaN  NaN        u8830      u8843           m   \n",
       "51768   NaN  NaN  NaN  NaN  NaN  NaN        u8830      u8843           m   \n",
       "51769   NaN  NaN  NaN  NaN  NaN  NaN        u8830      u8843           m   \n",
       "51770   NaN  NaN  NaN  NaN  NaN  NaN        u8830      u8843           m   \n",
       "51771   NaN  NaN  NaN  NaN  NaN  NaN        u8830      u8843           m   \n",
       "51772   NaN  NaN  NaN  NaN  NaN  NaN        u8830      u8843           m   \n",
       "51773   NaN  NaN  NaN  NaN  NaN  NaN        u8830      u8843           m   \n",
       "51774   NaN  NaN  NaN  NaN  NaN  NaN        u8830      u8843           m   \n",
       "51775   NaN  NaN  NaN  NaN  NaN  NaN        u8830      u8843           m   \n",
       "51776   NaN  NaN  NaN  NaN  NaN  NaN        u8830      u8843           m   \n",
       "51777   NaN  NaN  NaN  NaN  NaN  NaN        u8830      u8843           m   \n",
       "51778   NaN  NaN  NaN  NaN  NaN  NaN        u8830      u8843           m   \n",
       "51779   NaN  NaN  NaN  NaN  NaN  NaN        u8830      u8843           m   \n",
       "51780   NaN  NaN  NaN  NaN  NaN  NaN        u8830      u8843           m   \n",
       "51781   NaN  NaN  NaN  NaN  NaN  NaN        u8836      u8844           m   \n",
       "51782   NaN  NaN  NaN  NaN  NaN  NaN        u8836      u8844           m   \n",
       "51783   NaN  NaN  NaN  NaN  NaN  NaN        u8836      u8844           m   \n",
       "51784   NaN  NaN  NaN  NaN  NaN  NaN        u8836      u8844           m   \n",
       "51785   NaN  NaN  NaN  NaN  NaN  NaN        u8836      u8844           m   \n",
       "51786   NaN  NaN  NaN  NaN  NaN  NaN        u8836      u8844           m   \n",
       "51787   NaN  NaN  NaN  NaN  NaN  NaN        u8836      u8844           m   \n",
       "51788   NaN  NaN  NaN  NaN  NaN  NaN        u8836      u8844           m   \n",
       "51789   NaN  NaN  NaN  NaN  NaN  NaN        u8836      u8845           m   \n",
       "51790   NaN  NaN  NaN  NaN  NaN  NaN        u8836      u8845           m   \n",
       "51791   NaN  NaN  NaN  NaN  NaN  NaN        u8836      u8845           m   \n",
       "...     ...  ...  ...  ...  ...  ...          ...        ...         ...   \n",
       "103494  NaN  NaN  NaN  NaN  NaN  NaN        u7005      u7013           ?   \n",
       "103495  NaN  NaN  NaN  NaN  NaN  NaN        u7009      u7013           ?   \n",
       "103496  NaN  NaN  NaN  NaN  NaN  NaN        u7009      u7013           ?   \n",
       "103497  NaN  NaN  NaN  NaN  NaN  NaN        u7009      u7013           ?   \n",
       "103498  NaN  NaN  NaN  NaN  NaN  NaN        u7009      u7013           ?   \n",
       "103499  NaN  NaN  NaN  NaN  NaN  NaN        u7009      u7013           ?   \n",
       "103500  NaN  NaN  NaN  NaN  NaN  NaN        u7009      u7013           ?   \n",
       "103501  NaN  NaN  NaN  NaN  NaN  NaN        u7009      u7013           ?   \n",
       "103502  NaN  NaN  NaN  NaN  NaN  NaN        u2443      u2448           f   \n",
       "103503  NaN  NaN  NaN  NaN  NaN  NaN        u2443      u2448           f   \n",
       "103504  NaN  NaN  NaN  NaN  NaN  NaN        u2443      u2448           f   \n",
       "103505  NaN  NaN  NaN  NaN  NaN  NaN        u2443      u2448           f   \n",
       "103506  NaN  NaN  NaN  NaN  NaN  NaN        u2443      u2448           f   \n",
       "103507  NaN  NaN  NaN  NaN  NaN  NaN        u2443      u2448           f   \n",
       "103508  NaN  NaN  NaN  NaN  NaN  NaN        u2443      u2448           f   \n",
       "103509  NaN  NaN  NaN  NaN  NaN  NaN        u2443      u2448           f   \n",
       "103510  NaN  NaN  NaN  NaN  NaN  NaN        u2443      u2448           f   \n",
       "103511  NaN  NaN  NaN  NaN  NaN  NaN        u2443      u2448           f   \n",
       "103512  NaN  NaN  NaN  NaN  NaN  NaN        u2443      u2448           f   \n",
       "103513  NaN  NaN  NaN  NaN  NaN  NaN        u2444      u2448           ?   \n",
       "103514  NaN  NaN  NaN  NaN  NaN  NaN        u2444      u2448           ?   \n",
       "103515  NaN  NaN  NaN  NaN  NaN  NaN        u2444      u2448           ?   \n",
       "103516  NaN  NaN  NaN  NaN  NaN  NaN        u2444      u2448           ?   \n",
       "103517  NaN  NaN  NaN  NaN  NaN  NaN        u2444      u2448           ?   \n",
       "103518  NaN  NaN  NaN  NaN  NaN  NaN        u2444      u2448           ?   \n",
       "103519  NaN  NaN  NaN  NaN  NaN  NaN        u2444      u2448           ?   \n",
       "103520  NaN  NaN  NaN  NaN  NaN  NaN        u2444      u2448           ?   \n",
       "103521  NaN  NaN  NaN  NaN  NaN  NaN        u2444      u2448           ?   \n",
       "103522  NaN  NaN  NaN  NaN  NaN  NaN        u2443      u2452           f   \n",
       "103523  NaN  NaN  NaN  NaN  NaN  NaN        u2443      u2452           f   \n",
       "\n",
       "       gender_to   genre  line_id movie_id movie_year  \\\n",
       "51762          f   crime  L645156     m599       1987   \n",
       "51763          f   crime  L645157     m599       1987   \n",
       "51764          f   crime  L645158     m599       1987   \n",
       "51765          f   crime  L645159     m599       1987   \n",
       "51766          f   crime  L645160     m599       1987   \n",
       "51767          f   crime  L645161     m599       1987   \n",
       "51768          f   crime  L645162     m599       1987   \n",
       "51769          f   crime  L645163     m599       1987   \n",
       "51770          f   crime  L645164     m599       1987   \n",
       "51771          f   crime  L645253     m599       1987   \n",
       "51772          f   crime  L645254     m599       1987   \n",
       "51773          f   crime  L645356     m599       1987   \n",
       "51774          f   crime  L645357     m599       1987   \n",
       "51775          f   crime  L645358     m599       1987   \n",
       "51776          f   crime  L645359     m599       1987   \n",
       "51777          f   crime  L645360     m599       1987   \n",
       "51778          f   crime  L645362     m599       1987   \n",
       "51779          f   crime  L645363     m599       1987   \n",
       "51780          f   crime  L645364     m599       1987   \n",
       "51781          ?   crime  L645125     m599       1987   \n",
       "51782          ?   crime  L645126     m599       1987   \n",
       "51783          ?   crime  L645127     m599       1987   \n",
       "51784          ?   crime  L645128     m599       1987   \n",
       "51785          ?   crime  L645129     m599       1987   \n",
       "51786          ?   crime  L645130     m599       1987   \n",
       "51787          ?   crime  L645137     m599       1987   \n",
       "51788          ?   crime  L645138     m599       1987   \n",
       "51789          ?   crime  L645300     m599       1987   \n",
       "51790          ?   crime  L645301     m599       1987   \n",
       "51791          ?   crime  L645305     m599       1987   \n",
       "...          ...     ...      ...      ...        ...   \n",
       "103494         ?  action  L438133     m468       2001   \n",
       "103495         ?  action  L437710     m468       2001   \n",
       "103496         ?  action  L437711     m468       2001   \n",
       "103497         ?  action  L437712     m468       2001   \n",
       "103498         ?  action  L437714     m468       2001   \n",
       "103499         ?  action  L437715     m468       2001   \n",
       "103500         ?  action  L437716     m468       2001   \n",
       "103501         ?  action  L437717     m468       2001   \n",
       "103502         m  action  L436413     m157       2000   \n",
       "103503         m  action  L436414     m157       2000   \n",
       "103504         m  action  L436415     m157       2000   \n",
       "103505         m  action  L436416     m157       2000   \n",
       "103506         m  action  L436422     m157       2000   \n",
       "103507         m  action  L436423     m157       2000   \n",
       "103508         m  action  L436424     m157       2000   \n",
       "103509         m  action  L436465     m157       2000   \n",
       "103510         m  action  L436466     m157       2000   \n",
       "103511         m  action  L436467     m157       2000   \n",
       "103512         m  action  L436468     m157       2000   \n",
       "103513         m  action  L436364     m157       2000   \n",
       "103514         m  action  L436365     m157       2000   \n",
       "103515         m  action  L436366     m157       2000   \n",
       "103516         m  action  L436367     m157       2000   \n",
       "103517         m  action  L436368     m157       2000   \n",
       "103518         m  action  L436369     m157       2000   \n",
       "103519         m  action  L436435     m157       2000   \n",
       "103520         m  action  L436436     m157       2000   \n",
       "103521         m  action  L436437     m157       2000   \n",
       "103522         m  action  L436586     m157       2000   \n",
       "103523         m  action  L436587     m157       2000   \n",
       "\n",
       "                                                    words  \n",
       "51762                                                okay  \n",
       "51763   you i hear you guy handle fairchild food merge...  \n",
       "51764         come buddy you want get me disbar would you  \n",
       "51765            listen it one college buddy talk another  \n",
       "51766                                          yeah right  \n",
       "51767          relax roger everybody it you know you know  \n",
       "51768                                            i it moi  \n",
       "51769   money you ever dream roger thing one get hurt ...  \n",
       "51770                                     much i walk you  \n",
       "51771                                  you put dime roger  \n",
       "51772                                    right bud let it  \n",
       "51773                                             problem  \n",
       "51774   get strange call sec they ask see my record bu...  \n",
       "51775   relax roget you 82m account number i invisible...  \n",
       "51776   alright i wanna slow bud call awhile lunch we ...  \n",
       "51777                sure roger whatever you want it cool  \n",
       "51778   gekko ask u bluestar deal we review timetable ...  \n",
       "51779                                    he never tell me  \n",
       "51780                 you president company you know come  \n",
       "51781   rare pistol world larry 45 luger six ever manu...  \n",
       "51782   congratulation rare still your interest anacot...  \n",
       "51783   interest yours larry money i think it good inv...  \n",
       "51784   time i long term liquidation gordon i go turn ...  \n",
       "51785   you must wear mask you laugh hard behind it la...  \n",
       "51786   i could break you mate two piece my knee you k...  \n",
       "51787               consider you bring my mother it 71 50  \n",
       "51788                done you hear my lawyer 8 good night  \n",
       "51789              due respect mr gekko prevent you thing  \n",
       "51790   cause i way around way we make money make airl...  \n",
       "51791                             you prepare put writing  \n",
       "...                                                   ...  \n",
       "103494  we fail lose our carrier we destroy our abilit...  \n",
       "103495  you join u admiral u think your education amer...  \n",
       "103496  knowledge opponent careful calculation danger ...  \n",
       "103497  time come strike sit let american cut our oil ...  \n",
       "103498                         you something say yamamoto  \n",
       "103499  council know i oppose fight american matter gr...  \n",
       "103500                             you see u capable blow  \n",
       "103501  american themselves make it possible we annihi...  \n",
       "103502  i know you gabriel marion last time i saw you ...  \n",
       "103503                    i uh me it samuel i mean nathan  \n",
       "103504                it you it turn my teeth black month  \n",
       "103505                                            uh uh i  \n",
       "103506  i know you go look like i never would put ink ...  \n",
       "103507                                you call compliment  \n",
       "103508                                           it start  \n",
       "103509                         next time we bring blanket  \n",
       "103510                                         would nice  \n",
       "103511                    maybe we lucky winter rain snow  \n",
       "103512                                         would nice  \n",
       "103513                         he make light redcoat kill  \n",
       "103514                                      he make light  \n",
       "103515                              you know him well you  \n",
       "103516                                       he my father  \n",
       "103517                             i know him well enough  \n",
       "103518  fault him grow frontier it hard time hard plac...  \n",
       "103519                             you get salt last week  \n",
       "103520           oh right bake powder we need bake powder  \n",
       "103521  we get plenty bake powder you go pembroke get ...  \n",
       "103522                        i sorry we give you warning  \n",
       "103523                             it alright i happy you  \n",
       "\n",
       "[51762 rows x 15 columns]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_topics.iloc[testing[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/gensim/models/phrases.py:494: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    }
   ],
   "source": [
    "#need to split the data into chunks, too long right now!! \n",
    "\n",
    "data_words, id2word, corpus = prep_for_model(subset.words[:100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_gammas = model.inference(corpus)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "trunc_gammas = [x[:3] for x in test_gammas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7808"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_gammas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "topics[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "topics[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# coherence_values w 5,10,15,20 and w/o removing stop words (10 does best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# coherence_values w 4,8,12,16,20 and w/o removing stop words (8 does best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# trying the sklearn version\n",
    "\n",
    "texts = [men.words, women.words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ngram_range = [(1,1), (2,3)] # bag of words, bigrams and trigrams\n",
    "max_features = [1000]\n",
    "no_topics = [8, 10, 15]\n",
    "no_top_words = [5, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print (\"Topic %d:\" % (topic_idx))\n",
    "        print (\" ,\".join([feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
    "        \n",
    "# inspiration source: https://medium.com/mlreview/topic-modeling-with-scikit-learn-e80d33668730"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# only lda                       \n",
    "\n",
    "def topic_model(texts):\n",
    "\n",
    "    for a in ngram_range:\n",
    "        print (a)\n",
    "        for x in max_features:\n",
    "            print (x)\n",
    "            for y in no_topics: \n",
    "                print (y)\n",
    "                for text in texts: \n",
    "\n",
    "                    #transform\n",
    "                    count_vect = CountVectorizer(ngram_range = a, max_features = x, stop_words = 'english') # using bigrams and trigrams\n",
    "                    word_counts = count_vect.fit_transform(text, )\n",
    "                    tfidf_transformer = TfidfTransformer()\n",
    "                    words_tfidf = tfidf_transformer.fit_transform(word_counts)\n",
    "\n",
    "                    lda = LatentDirichletAllocation(n_topics=y, max_iter=5, learning_method='online', learning_offset=50.,random_state=0).fit(word_counts) \n",
    "                        \n",
    "                    for z in no_top_words: \n",
    "                        print (z)\n",
    "                        display_topics(lda, count_vect.get_feature_names(), z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "topic_model(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# transform\n",
    "count_vect = CountVectorizer(ngram_range = (2,3), max_features = 1000, stop_words = 'english') # using bigrams and trigrams\n",
    "w_words_counts = count_vect.fit_transform(women.words, )\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "w_words_tfidf = tfidf_transformer.fit_transform(w_words_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# transform\n",
    "#count_vect2 = CountVectorizer(ngram_range = (2,3)) # using bigrams and trigrams\n",
    "count_vect2 = CountVectorizer(ngram_range = (2,3), max_features = 1000, stop_words = 'english') # using bigrams and trigrams\n",
    "m_words_counts = count_vect2.fit_transform(men.words, )\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "m_words_tfidf = tfidf_transformer.fit_transform(m_words_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "nmf = NMF(n_components=20, random_state=1, alpha=.1, l1_ratio=.5, init='nndsvd').fit(w_words_tfidf)\n",
    "nmf2 = NMF(n_components=20, random_state=1, alpha=.1, l1_ratio=.5, init='nndsvd').fit(m_words_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Run LDA for women\n",
    "lda = LatentDirichletAllocation(n_topics=10, max_iter=5, learning_method='online', learning_offset=50.,random_state=0).fit(w_words_counts) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# LDA for men\n",
    "lda2 = LatentDirichletAllocation(n_topics=10, max_iter=5, learning_method='online', learning_offset=50.,random_state=0).fit(m_words_counts) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "no_top_words = 10\n",
    "display_topics(lda, count_vect.get_feature_names(), no_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "display_topics(lda2, count_vect.get_feature_names(), no_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "no_top_words = 10\n",
    "display_topics(nmf2, count_vect2.get_feature_names(), no_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# count_vect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# words_tfidf[1,:].toarray()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
